{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad3f018-80bf-4485-933e-b4f8809fada5",
   "metadata": {},
   "source": [
    "# Simulate and estimate a very simple Bayesian causal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "87afa7b7-8711-4df5-9610-34ac15531439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346e7bf2-b502-4c8e-9791-038428842e62",
   "metadata": {},
   "source": [
    "### Simulate a Bayesian latent variable model with perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a99abfa9-4aed-41f8-864b-0c7c57311d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "n_perturb = 5\n",
    "n_latent = 5\n",
    "n_features = 10\n",
    "n_obs = 1000\n",
    "\n",
    "# Prior distributions\n",
    "latent_mean = 0\n",
    "latent_std = 1\n",
    "\n",
    "# Define perturbation-latent space effect, should be sparse\n",
    "beta = stats.norm.rvs(scale=2, size=(n_perturb, n_latent))\n",
    "beta_mask = np.random.choice([0, 1], size=(n_perturb, n_latent)).astype(bool)\n",
    "beta[mask] = 0\n",
    "\n",
    "# Define latent-feature mapping, should be sparse\n",
    "W = stats.norm.rvs(scale=2, size=(n_latent, n_features))\n",
    "b = stats.norm.rvs(size=(1, n_features))\n",
    "W_mask = np.random.choice([0, 1], size=(n_latent, n_features)).astype(bool)\n",
    "W[W_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a51fa47d-32b9-4198-aefa-4b6256375ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the guide assignment matrix\n",
    "P = np.zeros((n_obs,n_perturb), dtype=int)\n",
    "for i in range(n_obs):\n",
    "    P[i, np.random.choice(n_perturb)] = 1\n",
    "\n",
    "# Generate the latent space variables\n",
    "Z = stats.norm.rvs(loc=latent_mean, scale=latent_std, size=(n_obs, n_latent))\n",
    "Z += P@beta\n",
    "\n",
    "# Generate means for X's\n",
    "X_means = Z@W+b\n",
    "X = stats.norm.rvs(loc=X_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3931e382-a476-40aa-9073-1fa0ac39dc60",
   "metadata": {},
   "source": [
    "### Create a Pyro model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fa63cdc2-57f5-48a3-8efc-f5d14b9593b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "from torch import nn\n",
    "from pyro.nn import PyroModule\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d1a606ea-ac5a-4747-84b9-49543bb5c3a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TorchDistributionMixin.__call__() got an unexpected keyword argument 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[165], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ag \u001b[38;5;241m=\u001b[39m \u001b[43mpyro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pyro/primitives.py:142\u001b[0m, in \u001b[0;36msample\u001b[0;34m(name, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrying to observe a value outside of inference at \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name,\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    140\u001b[0m         )\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obs\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# if stack not empty, apply everything in the stack?\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# initialize data structure to pass up/down the stack\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     msg \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    161\u001b[0m     }\n",
      "\u001b[0;31mTypeError\u001b[0m: TorchDistributionMixin.__call__() got an unexpected keyword argument 'size'"
     ]
    }
   ],
   "source": [
    "class BayesianRegression(PyroModule):\n",
    "    \n",
    "    def __init__(self, n_perturb, n_latent, n_features):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Declare beta as a variable\n",
    "        self.beta = PyroModule[nn.Linear](n_perturb, n_latent)\n",
    "        self.beta.weight = PyroSample(dist.Normal(0., 1.).expand([n_latent, n_perturb]).to_event(2))\n",
    "        self.beta.bias = PyroSample(dist.Normal(0., 1.).expand([n_latent]).to_event(1))\n",
    "        \n",
    "        # Declare mask as a variable\n",
    "        self.pi = \n",
    "        \n",
    "        # Define encoder\n",
    "        \n",
    "        # Define decoder\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))\n",
    "        mean = self.linear(x).squeeze(-1)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=y)\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f43c42-ff8d-49dd-b053-f68cbf2d811d",
   "metadata": {},
   "outputs": [],
   "source": [
    " def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = PyroModule[nn.Linear](in_features, out_features)\n",
    "        self.linear.weight = PyroSample(dist.Normal(0., 1.).expand([out_features, in_features]).to_event(2))\n",
    "        self.linear.bias = PyroSample(dist.Normal(0., 10.).expand([out_features]).to_event(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e0ad2-f1c4-4616-b491-afa71442acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X):\n",
    "    \n",
    "    _beta = pyro.sample(\"beta\", dist.Normal(0, 1))\n",
    "    \n",
    "    \n",
    "    a = pyro.sample(\"a\", dist.Normal(0., 10.))\n",
    "    b_a = pyro.sample(\"bA\", dist.Normal(0., 1.))\n",
    "    b_r = pyro.sample(\"bR\", dist.Normal(0., 1.))\n",
    "    b_ar = pyro.sample(\"bAR\", dist.Normal(0., 1.))\n",
    "    sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))\n",
    "    mean = a + b_a * is_cont_africa + b_r * ruggedness + b_ar * is_cont_africa * ruggedness\n",
    "    with pyro.plate(\"data\", len(ruggedness)):\n",
    "        pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=log_gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "747310ec-53be-48fb-9c7f-7381e7d3dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(is_cont_africa, ruggedness, log_gdp):\n",
    "    a = pyro.sample(\"a\", dist.Normal(0., 10.))\n",
    "    b_a = pyro.sample(\"bA\", dist.Normal(0., 1.))\n",
    "    b_r = pyro.sample(\"bR\", dist.Normal(0., 1.))\n",
    "    b_ar = pyro.sample(\"bAR\", dist.Normal(0., 1.))\n",
    "    sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))\n",
    "    mean = a + b_a * is_cont_africa + b_r * ruggedness + b_ar * is_cont_africa * ruggedness\n",
    "    with pyro.plate(\"data\", len(ruggedness)):\n",
    "        pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=log_gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932b00d-7c7c-43a9-a61e-c569e461f040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba183ba9-7e29-4146-bb8e-679f09004efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a1df8f5f-8b2e-463f-a266-faaac1a2f870",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 0 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mP\u001b[49m\u001b[38;5;129;43m@beta\u001b[39;49m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 0 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)"
     ]
    }
   ],
   "source": [
    "P@beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c2870b8c-e4f3-482f-907d-ec566e2b563f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.91002742, -0.92186503, -1.08265123,  0.10128784,  1.13183064],\n",
       "       [-0.27033453,  0.09442541, -0.21412823, -1.0213405 , -0.04262896],\n",
       "       [ 0.25084065,  0.22240159,  0.17268779,  0.25823634, -0.04667609],\n",
       "       ...,\n",
       "       [ 0.72570834,  0.65298513, -0.28390392, -1.10068273, -0.46834919],\n",
       "       [ 0.21971457,  1.48248596, -0.59271296,  1.06924575,  0.57892723],\n",
       "       [-0.24633521, -1.06654928, -0.4405091 ,  0.97873046,  0.77464404]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08456dd7-1750-43da-999f-6277b275bb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2cb8fb0d-7dcd-4cf5-833d-09eefde0d0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e03429db-6bc3-4a34-a3a7-f7412a525d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.18208369,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.80622373, -0.25971326,  1.73093022,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.61205513,  2.68592717,  0.24531006, -2.3916667 ],\n",
       "       [ 0.        ,  1.86658371,  0.        ,  0.02836729,  0.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e951cede-d462-4d90-840b-d30c31226c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model(data):\n",
    "\n",
    "#     # sample f from the Beta prior\n",
    "#     f = pyro.sample(\"latent_fairness\", dist.Beta(alpha0, beta0))\n",
    "    \n",
    "#     # loop over the observed data\n",
    "#     for i in range(len(data)):\n",
    "#         # observe datapoint i using the Bernoulli\n",
    "#         # likelihood Bernoulli(f)\n",
    "#         pyro.sample(\"obs_{}\".format(i), dist.Bernoulli(f), obs=data[i])\n",
    "        \n",
    "def model(data):\n",
    "    \n",
    "    # define the hyperparameters that control the Beta prior\n",
    "    alpha0 = torch.tensor(10.0)\n",
    "    beta0 = torch.tensor(10.0)\n",
    "    \n",
    "    # sample f from the beta prior\n",
    "    f = pyro.sample(\"latent_fairness\", dist.Beta(alpha0, beta0))\n",
    "    # loop over the observed data [WE ONLY CHANGE THE NEXT LINE]\n",
    "    for i in pyro.plate(\"data_loop\", len(data)):\n",
    "        # observe datapoint i using the bernoulli likelihood\n",
    "        pyro.sample(\"obs_{}\".format(i), dist.Bernoulli(f), obs=data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e15488e-a0bd-4d24-84c2-f9e06587771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(data):\n",
    "    \n",
    "    # register the two variational parameters with Pyro.\n",
    "    alpha_q = pyro.param(\"alpha_q\", torch.tensor(15.0),\n",
    "                         constraint=constraints.positive)\n",
    "    beta_q = pyro.param(\"beta_q\", torch.tensor(15.0),\n",
    "                        constraint=constraints.positive)\n",
    "    \n",
    "    # sample latent_fairness from the distribution Beta(alpha_q, beta_q)\n",
    "    pyro.sample(\"latent_fairness\", dist.Beta(alpha_q, beta_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6be4c39e-96df-41db-ae7c-6247b05f12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "smoke_test = ('CI' in os.environ)\n",
    "n_steps = 2 if smoke_test else 2000\n",
    "\n",
    "assert pyro.__version__.startswith('1.8.5')\n",
    "\n",
    "# clear the param store in case we're in a REPL\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# create some data with 6 observed heads and 4 observed tails\n",
    "data = []\n",
    "for _ in range(6):\n",
    "    data.append(torch.tensor(1.0))\n",
    "for _ in range(4):\n",
    "    data.append(torch.tensor(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9b26ac6-f5fb-45c6-b666-b00c223ad43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the optimizer\n",
    "adam_params = {\"lr\": 0.0005, \"betas\": (0.90, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "n_steps = 5000\n",
    "# do gradient steps\n",
    "for step in range(n_steps):\n",
    "    svi.step(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d63cd76-ad61-469e-9db5-8480af6945e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Based on the data and our prior belief, the fairness of the coin is 0.531 +- 0.090\n"
     ]
    }
   ],
   "source": [
    "# grab the learned variational parameters\n",
    "alpha_q = pyro.param(\"alpha_q\").item()\n",
    "beta_q = pyro.param(\"beta_q\").item()\n",
    "\n",
    "# here we use some facts about the Beta distribution\n",
    "# compute the inferred mean of the coin's fairness\n",
    "inferred_mean = alpha_q / (alpha_q + beta_q)\n",
    "\n",
    "# compute inferred standard deviation\n",
    "factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q))\n",
    "inferred_std = inferred_mean * math.sqrt(factor)\n",
    "\n",
    "print(\"\\nBased on the data and our prior belief, the fairness \" +\n",
    "      \"of the coin is %.3f +- %.3f\" % (inferred_mean, inferred_std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
