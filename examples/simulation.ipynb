{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad3f018-80bf-4485-933e-b4f8809fada5",
   "metadata": {},
   "source": [
    "# Simulate and estimate a very simple Bayesian causal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87afa7b7-8711-4df5-9610-34ac15531439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba464dea-a916-4c6b-90fa-63afa336248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "from torch import nn\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346e7bf2-b502-4c8e-9791-038428842e62",
   "metadata": {},
   "source": [
    "### Simulate a Bayesian latent variable model with perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a99abfa9-4aed-41f8-864b-0c7c57311d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "n_perturb = 5\n",
    "n_latent = 5\n",
    "n_features = 10\n",
    "n_obs = 1000\n",
    "\n",
    "# Prior distributions\n",
    "latent_mean = 0\n",
    "latent_std = 1\n",
    "\n",
    "# Define perturbation-latent space effect, should be sparse\n",
    "beta = stats.norm.rvs(scale=2, size=(n_perturb, n_latent))\n",
    "beta_mask = np.random.choice([0, 1], size=(n_perturb, n_latent)).astype(bool)\n",
    "beta[beta_mask] = 0\n",
    "\n",
    "# Define latent-feature mapping, should be sparse\n",
    "W = stats.norm.rvs(scale=2, size=(n_latent, n_features))\n",
    "b = stats.norm.rvs(size=(1, n_features))\n",
    "W_mask = np.random.choice([0, 1], size=(n_latent, n_features)).astype(bool)\n",
    "W[W_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a51fa47d-32b9-4198-aefa-4b6256375ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the guide assignment matrix\n",
    "P = np.zeros((n_obs,n_perturb), dtype=int)\n",
    "for i in range(n_obs):\n",
    "    P[i, np.random.choice(n_perturb)] = 1\n",
    "\n",
    "# Generate the latent space variables\n",
    "Z = stats.norm.rvs(loc=latent_mean, scale=latent_std, size=(n_obs, n_latent))\n",
    "Z += P@beta\n",
    "\n",
    "# Generate means for X's\n",
    "X_means = Z@W+b\n",
    "X = stats.norm.rvs(loc=X_means, scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86969b71-e302-4416-86cc-a87c3ee31770",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X).cuda()\n",
    "P = torch.tensor(P).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c171169f-562c-4612-92fd-e4f96fb51fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = X.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad3101b-f759-4ce1-b5c9-15c2e5b822b2",
   "metadata": {},
   "source": [
    "### Create a Pyro model for the easy case - treat Z like X's\n",
    "\n",
    "Basically a multiple multivariate regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3931e382-a476-40aa-9073-1fa0ac39dc60",
   "metadata": {},
   "source": [
    "### Create a Pyro model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1a606ea-ac5a-4747-84b9-49543bb5c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalLDAE(PyroModule):\n",
    "    \n",
    "    def __init__(self, n_perturb, n_latent, n_features):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Declare beta as a module\n",
    "        self.beta = PyroModule[nn.Linear](n_perturb, n_latent)\n",
    "        self.beta.weight = PyroSample(dist.Normal(tfn(0.), tfn(1.)).expand([n_latent, n_perturb]).to_event(2))\n",
    "        self.beta.bias = PyroSample(dist.Normal(tfn(0.), tfn(1.)).expand([n_latent]).to_event(1))\n",
    "        \n",
    "        # Define encoder\n",
    "        self.encoder = nn.Linear(n_features, n_latent).to(device)\n",
    "        \n",
    "        # Define decoder\n",
    "        self.decoder = nn.Linear(n_latent, n_features).to(device)\n",
    "\n",
    "    def forward(self, x, p):\n",
    "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))\n",
    "        effects = self.beta(p)\n",
    "        \n",
    "        # Sample the mask probabilities\n",
    "        prior_a = torch.ones((n_perturb, n_latent), device=X.device)\n",
    "        prior_b = torch.ones((n_perturb, n_latent), device=X.device)*n_perturb\n",
    "        \n",
    "        mask_prob = pyro.sample('mask_prob', dist.Beta(prior_a, prior_b))\n",
    "        \n",
    "        # Sample the mask\n",
    "        mask = pyro.sample('mask', dist.Bernoulli(mask_prob))\n",
    "        \n",
    "        masked_effects = self.beta\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=y)\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d185733-579d-4453-b6ad-3f0a79baf62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLDAE(\n",
       "  (beta): PyroLinear(in_features=5, out_features=5, bias=True)\n",
       "  (encoder): Encoder(\n",
       "    (fc1): Linear(in_features=784, out_features=2, bias=True)\n",
       "    (fc21): Linear(in_features=2, out_features=5, bias=True)\n",
       "    (fc22): Linear(in_features=2, out_features=5, bias=True)\n",
       "    (softplus): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       "  (decoder): Linear(in_features=5, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CausalLDAE(n_perturb, n_latent, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b695f0d-966d-4fde-888b-3160df627e99",
   "metadata": {},
   "source": [
    "### SUPER simple SPARSE bayesian regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f0636e8c-f1b7-41d6-a48c-ecc3d3a8da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1\n",
    "n= 1000\n",
    "labels = np.random.choice(2, size=n)\n",
    "means = beta*labels\n",
    "data = stats.norm.rvs(means, 1)\n",
    "\n",
    "labels = torch.tensor(labels).cuda()\n",
    "data = torch.tensor(data).cuda()\n",
    "device = labels.device\n",
    "\n",
    "def tfn(value, device=device):\n",
    "    \n",
    "    return torch.tensor(value, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7ca3b7e6-52a1-40d5-b3bb-33db5c366874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data, label):\n",
    "    \n",
    "    # Effect size \n",
    "    prior_es_mean = tfn(0)\n",
    "    prior_es_variance = tfn(10)\n",
    "    effect_size = pyro.sample('es', dist.Normal(prior_es_mean, prior_es_variance))\n",
    "    \n",
    "    # Mask probability\n",
    "    \n",
    "    \n",
    "    means = label*effect_size\n",
    "    \n",
    "    with pyro.plate(\"data\", len(data)):\n",
    "        pyro.sample('x', dist.Normal(means, tfn(1.)), obs=data)\n",
    "    \n",
    "def guide(x, label):\n",
    "    \n",
    "    mean_q = pyro.param('mean_q', tfn(0.))\n",
    "    var_q = pyro.param('var_q', tfn(1.), constraint=constraints.positive)\n",
    "    \n",
    "    pyro.sample('es', dist.Normal(mean_q, var_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0468caec-0458-481f-841e-4551f62bcf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_params = {\"lr\": 0.001, \"betas\": (0.90, 0.999)}\n",
    "optimizer = Adam(adam_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0058c4ad-6001-4f2c-9726-c00a597849b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "22906bf8-1cb5-4c2d-a71f-b7dd99d886d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=1.1017099392393317, intercept=-0.06815267501502076, rvalue=0.48943287007876385, pvalue=2.3282197303676225e-61, stderr=0.062136352612193496, intercept_stderr=0.04371679913252673)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.linregress(labels.to('cpu'), data.to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e96c7b7b-2f67-40f3-9012-8b561a7a670a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=0.955888673984559, intercept=-0.03551017655501176, rvalue=0.3862891932709075, pvalue=7.200627997075127e-05, stderr=0.23056348270902785, intercept_stderr=0.1563757621791224)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.linregress(labels.to('cpu'), data.to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d0ef82-f87a-446d-a471-8baea0654189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce16c139-1b4a-46fd-9253-e9c5732ac0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0806ea-72c9-4289-aa72-da2581e711b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fccfbcf3-90f6-41e9-a47c-156f57533a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 2.9425899982452393 0.4835539758205414\n"
     ]
    }
   ],
   "source": [
    "print(n, pyro.param('mean_q').item(), pyro.param('var_q').item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a566bc6-43b1-4590-acc5-c2fc058ffebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca42ad-ee9d-42da-9b79-5638e9381008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "39feb435-452f-49c1-92b8-c7d10e28d027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 2.9410760402679443 0.5252532362937927\n"
     ]
    }
   ],
   "source": [
    "print(n, pyro.param('mean_q').item(), pyro.param('var_q').item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "49b1e8d5-fcf4-4247-b887-f17c9f581a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 2.9311881065368652 0.5552800297737122\n"
     ]
    }
   ],
   "source": [
    "# print(n, pyro.param('mean_q').item(), pyro.param('var_q').item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87afe081-2352-46bf-bf03-9755b66f8a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614ff69e-fddb-45a6-b9eb-ce1842abdaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c0278f-2e99-4998-8419-0c460fbd50ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f1560d-a084-4473-bd95-d5dc00a06d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9afe6f22-010b-49f8-879d-d09649675ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 2.922926902770996 0.5885440111160278\n"
     ]
    }
   ],
   "source": [
    "print('1000', pyro.param('mean_q').item(), pyro.param('var_q').item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3358e76f-d359-4126-b9d2-ed211653db86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818b4cb-40fc-4852-baf7-c4cdf37e1bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f43c42-ff8d-49dd-b053-f68cbf2d811d",
   "metadata": {},
   "outputs": [],
   "source": [
    " def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = PyroModule[nn.Linear](in_features, out_features)\n",
    "        self.linear.weight = PyroSample(dist.Normal(0., 1.).expand([out_features, in_features]).to_event(2))\n",
    "        self.linear.bias = PyroSample(dist.Normal(0., 10.).expand([out_features]).to_event(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e0ad2-f1c4-4616-b491-afa71442acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X):\n",
    "    \n",
    "    _beta = pyro.sample(\"beta\", dist.Normal(0, 1))\n",
    "    \n",
    "    \n",
    "    a = pyro.sample(\"a\", dist.Normal(0., 10.))\n",
    "    b_a = pyro.sample(\"bA\", dist.Normal(0., 1.))\n",
    "    b_r = pyro.sample(\"bR\", dist.Normal(0., 1.))\n",
    "    b_ar = pyro.sample(\"bAR\", dist.Normal(0., 1.))\n",
    "    sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))\n",
    "    mean = a + b_a * is_cont_africa + b_r * ruggedness + b_ar * is_cont_africa * ruggedness\n",
    "    with pyro.plate(\"data\", len(ruggedness)):\n",
    "        pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=log_gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "747310ec-53be-48fb-9c7f-7381e7d3dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(is_cont_africa, ruggedness, log_gdp):\n",
    "    a = pyro.sample(\"a\", dist.Normal(0., 10.))\n",
    "    b_a = pyro.sample(\"bA\", dist.Normal(0., 1.))\n",
    "    b_r = pyro.sample(\"bR\", dist.Normal(0., 1.))\n",
    "    b_ar = pyro.sample(\"bAR\", dist.Normal(0., 1.))\n",
    "    sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))\n",
    "    mean = a + b_a * is_cont_africa + b_r * ruggedness + b_ar * is_cont_africa * ruggedness\n",
    "    with pyro.plate(\"data\", len(ruggedness)):\n",
    "        pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=log_gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932b00d-7c7c-43a9-a61e-c569e461f040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba183ba9-7e29-4146-bb8e-679f09004efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a1df8f5f-8b2e-463f-a266-faaac1a2f870",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 0 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mP\u001b[49m\u001b[38;5;129;43m@beta\u001b[39;49m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 0 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)"
     ]
    }
   ],
   "source": [
    "P@beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c2870b8c-e4f3-482f-907d-ec566e2b563f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.91002742, -0.92186503, -1.08265123,  0.10128784,  1.13183064],\n",
       "       [-0.27033453,  0.09442541, -0.21412823, -1.0213405 , -0.04262896],\n",
       "       [ 0.25084065,  0.22240159,  0.17268779,  0.25823634, -0.04667609],\n",
       "       ...,\n",
       "       [ 0.72570834,  0.65298513, -0.28390392, -1.10068273, -0.46834919],\n",
       "       [ 0.21971457,  1.48248596, -0.59271296,  1.06924575,  0.57892723],\n",
       "       [-0.24633521, -1.06654928, -0.4405091 ,  0.97873046,  0.77464404]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08456dd7-1750-43da-999f-6277b275bb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2cb8fb0d-7dcd-4cf5-833d-09eefde0d0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e03429db-6bc3-4a34-a3a7-f7412a525d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.18208369,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.80622373, -0.25971326,  1.73093022,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.61205513,  2.68592717,  0.24531006, -2.3916667 ],\n",
       "       [ 0.        ,  1.86658371,  0.        ,  0.02836729,  0.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e951cede-d462-4d90-840b-d30c31226c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model(data):\n",
    "\n",
    "#     # sample f from the Beta prior\n",
    "#     f = pyro.sample(\"latent_fairness\", dist.Beta(alpha0, beta0))\n",
    "    \n",
    "#     # loop over the observed data\n",
    "#     for i in range(len(data)):\n",
    "#         # observe datapoint i using the Bernoulli\n",
    "#         # likelihood Bernoulli(f)\n",
    "#         pyro.sample(\"obs_{}\".format(i), dist.Bernoulli(f), obs=data[i])\n",
    "        \n",
    "def model(data):\n",
    "    \n",
    "    # define the hyperparameters that control the Beta prior\n",
    "    alpha0 = torch.tensor(10.0)\n",
    "    beta0 = torch.tensor(10.0)\n",
    "    \n",
    "    # sample f from the beta prior\n",
    "    f = pyro.sample(\"latent_fairness\", dist.Beta(alpha0, beta0))\n",
    "    # loop over the observed data [WE ONLY CHANGE THE NEXT LINE]\n",
    "    for i in pyro.plate(\"data_loop\", len(data)):\n",
    "        # observe datapoint i using the bernoulli likelihood\n",
    "        pyro.sample(\"obs_{}\".format(i), dist.Bernoulli(f), obs=data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e15488e-a0bd-4d24-84c2-f9e06587771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(data):\n",
    "    \n",
    "    # register the two variational parameters with Pyro.\n",
    "    alpha_q = pyro.param(\"alpha_q\", torch.tensor(15.0),\n",
    "                         constraint=constraints.positive)\n",
    "    beta_q = pyro.param(\"beta_q\", torch.tensor(15.0),\n",
    "                        constraint=constraints.positive)\n",
    "    \n",
    "    # sample latent_fairness from the distribution Beta(alpha_q, beta_q)\n",
    "    pyro.sample(\"latent_fairness\", dist.Beta(alpha_q, beta_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6be4c39e-96df-41db-ae7c-6247b05f12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "smoke_test = ('CI' in os.environ)\n",
    "n_steps = 2 if smoke_test else 2000\n",
    "\n",
    "assert pyro.__version__.startswith('1.8.5')\n",
    "\n",
    "# clear the param store in case we're in a REPL\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# create some data with 6 observed heads and 4 observed tails\n",
    "data = []\n",
    "for _ in range(6):\n",
    "    data.append(torch.tensor(1.0))\n",
    "for _ in range(4):\n",
    "    data.append(torch.tensor(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9b26ac6-f5fb-45c6-b666-b00c223ad43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the optimizer\n",
    "adam_params = {\"lr\": 0.0005, \"betas\": (0.90, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "n_steps = 5000\n",
    "# do gradient steps\n",
    "for step in range(n_steps):\n",
    "    svi.step(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d63cd76-ad61-469e-9db5-8480af6945e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Based on the data and our prior belief, the fairness of the coin is 0.531 +- 0.090\n"
     ]
    }
   ],
   "source": [
    "# grab the learned variational parameters\n",
    "alpha_q = pyro.param(\"alpha_q\").item()\n",
    "beta_q = pyro.param(\"beta_q\").item()\n",
    "\n",
    "# here we use some facts about the Beta distribution\n",
    "# compute the inferred mean of the coin's fairness\n",
    "inferred_mean = alpha_q / (alpha_q + beta_q)\n",
    "\n",
    "# compute inferred standard deviation\n",
    "factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q))\n",
    "inferred_std = inferred_mean * math.sqrt(factor)\n",
    "\n",
    "print(\"\\nBased on the data and our prior belief, the fairness \" +\n",
    "      \"of the coin is %.3f +- %.3f\" % (inferred_mean, inferred_std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
